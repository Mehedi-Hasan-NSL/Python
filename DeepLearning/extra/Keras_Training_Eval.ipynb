{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9df6c7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T12:14:25.277946Z",
     "start_time": "2021-09-20T12:14:18.777975Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86a8857c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T12:14:27.412289Z",
     "start_time": "2021-09-20T12:14:26.987761Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29ba731e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-27T10:27:08.134778Z",
     "start_time": "2021-07-27T10:27:08.116567Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "479c5928",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-27T10:31:41.128421Z",
     "start_time": "2021-07-27T10:31:40.567625Z"
    }
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Preprocess the data (these are NumPy arrays)\n",
    "x_train = x_train.reshape(60000, 784).astype(\"float32\") / 255\n",
    "x_test = x_test.reshape(10000, 784).astype(\"float32\") / 255\n",
    "\n",
    "y_train = y_train.astype(\"float32\")\n",
    "y_test = y_test.astype(\"float32\")\n",
    "\n",
    "# Reserve 10,000 samples for validation\n",
    "x_val = x_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "x_train = x_train[:-10000]\n",
    "y_train = y_train[:-10000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb8f09a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-27T10:32:02.936596Z",
     "start_time": "2021-07-27T10:32:02.838853Z"
    }
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "outputs = layers.Dense(10, activation=\"softmax\", name=\"predictions\")(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92cdd4ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-27T10:35:39.441174Z",
     "start_time": "2021-07-27T10:35:39.414275Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(),  # Optimizer\n",
    "    # Loss function to minimize\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    # List of metrics to monitor\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy(),'mse'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c0fcab8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-27T10:39:47.728369Z",
     "start_time": "2021-07-27T10:39:45.078939Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit model on training data\n",
      "Epoch 1/2\n",
      "782/782 [==============================] - 1s 2ms/step - loss: 0.0740 - sparse_categorical_accuracy: 0.9767 - mse: 27.3582 - val_loss: 0.0991 - val_sparse_categorical_accuracy: 0.9712 - val_mse: 27.5540\n",
      "Epoch 2/2\n",
      "782/782 [==============================] - 1s 2ms/step - loss: 0.0629 - sparse_categorical_accuracy: 0.9809 - mse: 27.3587 - val_loss: 0.1032 - val_sparse_categorical_accuracy: 0.9708 - val_mse: 27.5549\n"
     ]
    }
   ],
   "source": [
    "print(\"Fit model on training data\")\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=64,\n",
    "    epochs=2,\n",
    "    verbose=1,\n",
    "    # We pass some validation for\n",
    "    # monitoring validation loss and metrics\n",
    "    # at the end of each epoch\n",
    "    validation_data=(x_val, y_val),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6b3d2d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-27T10:40:06.736281Z",
     "start_time": "2021-07-27T10:40:06.718317Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.07402514666318893, 0.06285056471824646],\n",
       " 'sparse_categorical_accuracy': [0.9767400026321411, 0.9808800220489502],\n",
       " 'mse': [27.358200073242188, 27.35873031616211],\n",
       " 'val_loss': [0.09911438822746277, 0.10318354517221451],\n",
       " 'val_sparse_categorical_accuracy': [0.9711999893188477, 0.97079998254776],\n",
       " 'val_mse': [27.553958892822266, 27.554887771606445]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0fc3cb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-27T10:41:51.172544Z",
     "start_time": "2021-07-27T10:41:50.914021Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on test data\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.1078 - sparse_categorical_accuracy: 0.9691 - mse: 27.3373\n",
      "test loss, test acc, mse: [0.10782857984304428, 0.9690999984741211, 27.337263107299805]\n",
      "Generate predictions for 3 samples\n",
      "predictions shape: (3, 10)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data using `evaluate`\n",
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(x_test, y_test, batch_size=128)\n",
    "print(\"test loss, test acc, mse:\", results)\n",
    "\n",
    "# Generate predictions (probabilities -- the output of the last layer)\n",
    "# on new data using `predict`\n",
    "print(\"Generate predictions for 3 samples\")\n",
    "predictions = model.predict(x_test[:3])\n",
    "print(\"predictions shape:\", predictions.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b77de3e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-28T02:19:35.990232Z",
     "start_time": "2021-07-28T02:19:35.916977Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_uncompiled_model():\n",
    "    inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "    x = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "    x = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "    outputs = layers.Dense(10, activation=\"softmax\", name=\"predictions\")(x)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_compiled_model():\n",
    "    model = get_uncompiled_model()\n",
    "    model.compile(\n",
    "        optimizer=\"rmsprop\",\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"sparse_categorical_accuracy\"],\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32954f8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T02:21:38.191261Z",
     "start_time": "2021-07-30T02:21:38.180697Z"
    }
   },
   "outputs": [],
   "source": [
    "def custom_mean_squared_error(y_true, y_pred):\n",
    "    return tf.math.reduce_mean(tf.square(y_true - y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46281e40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T02:37:57.244948Z",
     "start_time": "2021-07-30T02:37:54.374373Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]], shape=(10, 10), dtype=float32)\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.0156\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2554b266700>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_uncompiled_model()\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss=custom_mean_squared_error)\n",
    "\n",
    "# We need to one-hot encode the labels to use MSE\n",
    "y_train_one_hot = tf.one_hot(y_train, depth=10)\n",
    "#print(y_train_one_hot[:10])\n",
    "model.fit(x_train, y_train_one_hot, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f197ac71",
   "metadata": {},
   "source": [
    "# Custom Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fdafac25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T02:39:37.899099Z",
     "start_time": "2021-07-30T02:39:35.506112Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step - loss: 0.0389\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25547f9f310>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CustomMSE(keras.losses.Loss):\n",
    "    def __init__(self, regularization_factor=0.1, name=\"custom_mse\"):\n",
    "        super().__init__(name=name)\n",
    "        self.regularization_factor = regularization_factor\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        mse = tf.math.reduce_mean(tf.square(y_true - y_pred))\n",
    "        reg = tf.math.reduce_mean(tf.square(0.5 - y_pred))\n",
    "        return mse + reg * self.regularization_factor\n",
    "\n",
    "\n",
    "model = get_uncompiled_model()\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss=CustomMSE())\n",
    "\n",
    "y_train_one_hot = tf.one_hot(y_train, depth=10)\n",
    "model.fit(x_train, y_train_one_hot, batch_size=64, epochs=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288fa469",
   "metadata": {},
   "source": [
    "# Custom Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75a0e2e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T02:40:30.216509Z",
     "start_time": "2021-07-30T02:40:25.594447Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "782/782 [==============================] - 1s 2ms/step - loss: 0.3464 - categorical_true_positives: 45134.0000\n",
      "Epoch 2/3\n",
      "782/782 [==============================] - 1s 2ms/step - loss: 0.1653 - categorical_true_positives: 47564.0000\n",
      "Epoch 3/3\n",
      "782/782 [==============================] - 1s 2ms/step - loss: 0.1180 - categorical_true_positives: 48234.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2554d283a30>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CategoricalTruePositives(keras.metrics.Metric):\n",
    "    def __init__(self, name=\"categorical_true_positives\", **kwargs):\n",
    "        super(CategoricalTruePositives, self).__init__(name=name, **kwargs)\n",
    "        self.true_positives = self.add_weight(name=\"ctp\", initializer=\"zeros\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_pred = tf.reshape(tf.argmax(y_pred, axis=1), shape=(-1, 1))\n",
    "        values = tf.cast(y_true, \"int32\") == tf.cast(y_pred, \"int32\")\n",
    "        values = tf.cast(values, \"float32\")\n",
    "        if sample_weight is not None:\n",
    "            sample_weight = tf.cast(sample_weight, \"float32\")\n",
    "            values = tf.multiply(values, sample_weight)\n",
    "        self.true_positives.assign_add(tf.reduce_sum(values))\n",
    "\n",
    "    def result(self):\n",
    "        return self.true_positives\n",
    "\n",
    "    def reset_states(self):\n",
    "        # The state of the metric will be reset at the start of each epoch.\n",
    "        self.true_positives.assign(0.0)\n",
    "\n",
    "\n",
    "model = get_uncompiled_model()\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(learning_rate=1e-3),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[CategoricalTruePositives()],\n",
    ")\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f53f438",
   "metadata": {},
   "source": [
    "# Custom ActivityRegularization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4cad536c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T02:43:29.283063Z",
     "start_time": "2021-07-30T02:43:27.238221Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 2ms/step - loss: 2.4784\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2554e5770d0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ActivityRegularizationLayer(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        self.add_loss(tf.reduce_sum(inputs) * 0.1)\n",
    "        return inputs  # Pass-through layer.\n",
    "\n",
    "\n",
    "inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "\n",
    "# Insert activity regularization as a layer\n",
    "x = ActivityRegularizationLayer()(x)\n",
    "\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "outputs = layers.Dense(10, name=\"predictions\")(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(learning_rate=1e-3),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    ")\n",
    "\n",
    "# The displayed loss will be much higher than before\n",
    "# due to the regularization component.\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "30891d06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T02:44:15.174043Z",
     "start_time": "2021-07-30T02:44:13.350441Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 2ms/step - loss: 0.3452 - std_of_activation: 0.9782\n",
      "Model: \"functional_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "digits (InputLayer)          [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "metric_logging_layer_1 (Metr (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 55,050\n",
      "Trainable params: 55,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class MetricLoggingLayer(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        # The `aggregation` argument defines\n",
    "        # how to aggregate the per-batch values\n",
    "        # over each epoch:\n",
    "        # in this case we simply average them.\n",
    "        self.add_metric(\n",
    "            keras.backend.std(inputs), name=\"std_of_activation\", aggregation=\"mean\"\n",
    "        )\n",
    "        return inputs  # Pass-through layer.\n",
    "\n",
    "\n",
    "inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "\n",
    "# Insert std logging as a layer.\n",
    "x = MetricLoggingLayer()(x)\n",
    "\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "outputs = layers.Dense(10, name=\"predictions\")(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(learning_rate=1e-3),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    ")\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=1)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4856322f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T02:45:21.658594Z",
     "start_time": "2021-07-30T02:45:18.370924Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 2ms/step - loss: 2.4721 - std_of_activation: 0.0018\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x255501c5d00>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "x1 = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "x2 = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x1)\n",
    "outputs = layers.Dense(10, name=\"predictions\")(x2)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.add_loss(tf.reduce_sum(x1) * 0.1)\n",
    "\n",
    "model.add_metric(keras.backend.std(x1), name=\"std_of_activation\", aggregation=\"mean\")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    ")\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3d15b3",
   "metadata": {},
   "source": [
    "# Tensor Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ba1c0014",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T05:47:53.986815Z",
     "start_time": "2021-07-30T05:47:47.378064Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "782/782 [==============================] - 1s 2ms/step - loss: 0.3433 - sparse_categorical_accuracy: 0.9030\n",
      "Epoch 2/3\n",
      "782/782 [==============================] - 1s 2ms/step - loss: 0.1674 - sparse_categorical_accuracy: 0.9494\n",
      "Epoch 3/3\n",
      "782/782 [==============================] - 1s 2ms/step - loss: 0.1229 - sparse_categorical_accuracy: 0.9634\n",
      "Evaluate\n",
      "157/157 [==============================] - 0s 867us/step - loss: 0.1208 - sparse_categorical_accuracy: 0.9636\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.12083735316991806,\n",
       " 'sparse_categorical_accuracy': 0.9635999798774719}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_compiled_model()\n",
    "\n",
    "# First, let's create a training Dataset instance.\n",
    "# For the sake of our example, we'll use the same MNIST data as before.\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "# Shuffle and slice the dataset.\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "# Now we get a test dataset.\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "test_dataset = test_dataset.batch(64)\n",
    "\n",
    "# Since the dataset already takes care of batching,\n",
    "# we don't pass a `batch_size` argument.\n",
    "model.fit(train_dataset, epochs=3)\n",
    "\n",
    "# You can also evaluate or predict on a dataset.\n",
    "print(\"Evaluate\")\n",
    "result = model.evaluate(test_dataset)\n",
    "dict(zip(model.metrics_names, result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9b8e07fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T05:50:38.513445Z",
     "start_time": "2021-07-30T05:50:36.884279Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8092 - sparse_categorical_accuracy: 0.7795\n",
      "Epoch 2/3\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.3766 - sparse_categorical_accuracy: 0.8958\n",
      "Epoch 3/3\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.3185 - sparse_categorical_accuracy: 0.9070\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2554d5924c0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_compiled_model()\n",
    "\n",
    "# Prepare the training dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "# Only use the 100 batches per epoch (that's 64 * 100 samples)\n",
    "model.fit(train_dataset, epochs=3, steps_per_epoch=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "12908852",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T05:54:47.752819Z",
     "start_time": "2021-07-30T05:54:44.147401Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 2s 3ms/step - loss: 0.3326 - sparse_categorical_accuracy: 0.9060 - val_loss: 0.1942 - val_sparse_categorical_accuracy: 0.9429\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x255516f6310>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########### using validation_dataset ##########\n",
    "\n",
    "model = get_compiled_model()\n",
    "\n",
    "# Prepare the training dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "# Prepare the validation dataset\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "val_dataset = val_dataset.batch(64)\n",
    "\n",
    "model.fit(train_dataset, epochs=1, validation_data=val_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d3e1c63c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T06:00:02.055499Z",
     "start_time": "2021-07-30T05:59:54.456273Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.3366 - sparse_categorical_accuracy: 0.9048 - val_loss: 0.3162 - val_sparse_categorical_accuracy: 0.9125\n",
      "Epoch 2/3\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.1606 - sparse_categorical_accuracy: 0.9528 - val_loss: 0.2346 - val_sparse_categorical_accuracy: 0.9438\n",
      "Epoch 3/3\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.1151 - sparse_categorical_accuracy: 0.9653 - val_loss: 0.1453 - val_sparse_categorical_accuracy: 0.9578\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25552ecd5b0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_compiled_model()\n",
    "\n",
    "# Prepare the training dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "# Prepare the validation dataset\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "val_dataset = val_dataset.batch(64)\n",
    "\n",
    "model.fit(\n",
    "    train_dataset,\n",
    "    epochs=3,\n",
    "    # Only run validation using the first 10 batches of the dataset\n",
    "    # using the `validation_steps` argument\n",
    "    validation_data=val_dataset,\n",
    "    validation_steps=10,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e249441",
   "metadata": {},
   "source": [
    "# DATASET\n",
    "Besides NumPy arrays, eager tensors, and TensorFlow Datasets, it's possible to train a Keras model using Pandas dataframes, or from Python generators that yield batches of data & labels.\n",
    "\n",
    "In particular, the keras.utils.Sequence class offers a simple interface to build Python data generators that are multiprocessing-aware and can be shuffled.\n",
    "\n",
    "In general, we recommend that you use:\n",
    "\n",
    "    1 NumPy input data if your data is small and fits in memory\n",
    "    2 Dataset objects if you have large datasets and you need to do distributed training\n",
    "    3 Sequence objects if you have large datasets and you need to do a lot of custom Python-side processing that cannot be done in TensorFlow (e.g. if you rely on external libraries for data loading or preprocessing).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b8e12376",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T06:08:14.525601Z",
     "start_time": "2021-07-30T06:08:14.421439Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filenames' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-5dec3526fa8a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m                for filename in batch_x]), np.array(batch_y)\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0msequence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCIFAR10Sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'filenames' is not defined"
     ]
    }
   ],
   "source": [
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "import numpy as np\n",
    "from keras.utils import Sequence\n",
    "\n",
    "\n",
    "# Here, `filenames` is list of path to the images\n",
    "# and `labels` are the associated labels.\n",
    "\n",
    "class CIFAR10Sequence(Sequence):\n",
    "    def __init__(self, filenames, labels, batch_size):\n",
    "        self.filenames, self.labels = filenames, labels\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.filenames) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.filenames[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.labels[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        return np.array([\n",
    "            resize(imread(filename), (200, 200))\n",
    "               for filename in batch_x]), np.array(batch_y)\n",
    "\n",
    "sequence = CIFAR10Sequence(filenames, labels, batch_size)\n",
    "model.fit(sequence, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53d573c",
   "metadata": {},
   "source": [
    "# Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "75b2343e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T06:13:28.852219Z",
     "start_time": "2021-07-30T06:13:19.584735Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "625/625 [==============================] - 2s 2ms/step - loss: 0.3555 - sparse_categorical_accuracy: 0.8989 - val_loss: 0.2447 - val_sparse_categorical_accuracy: 0.9242\n",
      "Epoch 2/20\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.1670 - sparse_categorical_accuracy: 0.9504 - val_loss: 0.1807 - val_sparse_categorical_accuracy: 0.9438\n",
      "Epoch 3/20\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.1221 - sparse_categorical_accuracy: 0.9633 - val_loss: 0.1559 - val_sparse_categorical_accuracy: 0.9528\n",
      "Epoch 4/20\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.0956 - sparse_categorical_accuracy: 0.9709 - val_loss: 0.1415 - val_sparse_categorical_accuracy: 0.9574\n",
      "Epoch 5/20\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.0788 - sparse_categorical_accuracy: 0.9760 - val_loss: 0.1570 - val_sparse_categorical_accuracy: 0.9540\n",
      "Epoch 6/20\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.0659 - sparse_categorical_accuracy: 0.9796 - val_loss: 0.1425 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 00006: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2555f4d2e50>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_compiled_model()\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        # Stop training when `val_loss` is no longer improving\n",
    "        monitor=\"val_loss\",\n",
    "        # \"no longer improving\" being defined as \"no better than 1e-2 less\"\n",
    "        min_delta=1e-2,\n",
    "        # \"no longer improving\" being further defined as \"for at least 2 epochs\"\n",
    "        patience=2,\n",
    "        verbose=1,\n",
    "    )\n",
    "]\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=20,\n",
    "    batch_size=64,\n",
    "    callbacks=callbacks,\n",
    "    validation_split=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "926b8822",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T06:13:43.031934Z",
     "start_time": "2021-07-30T06:13:43.005416Z"
    }
   },
   "outputs": [],
   "source": [
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs):\n",
    "        self.per_batch_losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        self.per_batch_losses.append(logs.get(\"loss\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8f438fa3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T06:13:57.771370Z",
     "start_time": "2021-07-30T06:13:49.919126Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "616/625 [============================>.] - ETA: 0s - loss: 0.3793 - sparse_categorical_accuracy: 0.8916\n",
      "Epoch 00001: val_loss improved from inf to 0.23974, saving model to mymodel_1\n",
      "WARNING:tensorflow:From C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: mymodel_1\\assets\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.3771 - sparse_categorical_accuracy: 0.8923 - val_loss: 0.2397 - val_sparse_categorical_accuracy: 0.9265\n",
      "Epoch 2/2\n",
      "622/625 [============================>.] - ETA: 0s - loss: 0.1808 - sparse_categorical_accuracy: 0.9462\n",
      "Epoch 00002: val_loss improved from 0.23974 to 0.19989, saving model to mymodel_2\n",
      "INFO:tensorflow:Assets written to: mymodel_2\\assets\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 0.1809 - sparse_categorical_accuracy: 0.9462 - val_loss: 0.1999 - val_sparse_categorical_accuracy: 0.9388\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25560ac6af0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_compiled_model()\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        # Path where to save the model\n",
    "        # The two parameters below mean that we will overwrite\n",
    "        # the current checkpoint if and only if\n",
    "        # the `val_loss` score has improved.\n",
    "        # The saved model name will include the current epoch.\n",
    "        filepath=\"mymodel_{epoch}\",\n",
    "        save_best_only=True,  # Only save a model if `val_loss` has improved.\n",
    "        monitor=\"val_loss\",\n",
    "        verbose=1,\n",
    "    )\n",
    "]\n",
    "model.fit(\n",
    "    x_train, y_train, epochs=2, batch_size=64, callbacks=callbacks, validation_split=0.2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8673e308",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T06:39:35.160598Z",
     "start_time": "2021-07-30T06:39:13.500477Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./ckpt/ckpt-loss=0.31', './ckpt/ckpt-loss=0.32', './ckpt/ckpt-loss=0.33', './ckpt/ckpt-loss=0.34', './ckpt/ckpt-loss=0.35', './ckpt/ckpt-loss=0.37', './ckpt/ckpt-loss=0.38', './ckpt/ckpt-loss=0.40', './ckpt/ckpt-loss=0.42', './ckpt/ckpt-loss=0.45', './ckpt/ckpt-loss=0.48', './ckpt/ckpt-loss=0.53', './ckpt/ckpt-loss=0.60', './ckpt/ckpt-loss=0.72', './ckpt/ckpt-loss=1.02']\n",
      "Restoring from ./ckpt/ckpt-loss=0.31\n",
      "  97/1563 [>.............................] - ETA: 2s - loss: 0.1779 - sparse_categorical_accuracy: 0.9526INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.18\\assets\n",
      " 170/1563 [==>...........................] - ETA: 9s - loss: 0.1732 - sparse_categorical_accuracy: 0.9500 INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.17\\assets\n",
      " 276/1563 [====>.........................] - ETA: 10s - loss: 0.1569 - sparse_categorical_accuracy: 0.9536INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.16\\assets\n",
      " 369/1563 [======>.......................] - ETA: 11s - loss: 0.1575 - sparse_categorical_accuracy: 0.9534INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.16\\assets\n",
      " 464/1563 [=======>......................] - ETA: 10s - loss: 0.1597 - sparse_categorical_accuracy: 0.9526INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.16\\assets\n",
      " 568/1563 [=========>....................] - ETA: 9s - loss: 0.1574 - sparse_categorical_accuracy: 0.9525 INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.16\\assets\n",
      " 674/1563 [===========>..................] - ETA: 9s - loss: 0.1579 - sparse_categorical_accuracy: 0.9525INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.16\\assets\n",
      " 766/1563 [=============>................] - ETA: 8s - loss: 0.1566 - sparse_categorical_accuracy: 0.9526INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.16\\assets\n",
      " 863/1563 [===============>..............] - ETA: 7s - loss: 0.1562 - sparse_categorical_accuracy: 0.9531INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.15\\assets\n",
      " 968/1563 [=================>............] - ETA: 5s - loss: 0.1527 - sparse_categorical_accuracy: 0.9545INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.15\\assets\n",
      "1099/1563 [====================>.........] - ETA: 4s - loss: 0.1517 - sparse_categorical_accuracy: 0.9545- ETA: 5s - loss: 0.1515 - sparse_categorical_accuracy: 0.95INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.15\\assets\n",
      "1166/1563 [=====================>........] - ETA: 4s - loss: 0.1518 - sparse_categorical_accuracy: 0.9545INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.15\\assets\n",
      "1268/1563 [=======================>......] - ETA: 3s - loss: 0.1513 - sparse_categorical_accuracy: 0.9546INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.15\\assets\n",
      "1399/1563 [=========================>....] - ETA: 1s - loss: 0.1497 - sparse_categorical_accuracy: 0.9550INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.15\\assets\n",
      "1497/1563 [===========================>..] - ETA: 0s - loss: 0.1490 - sparse_categorical_accuracy: 0.9553INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.15\\assets\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.1478 - sparse_categorical_accuracy: 0.9555\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x255625e7070>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Prepare a directory to store all the checkpoints.\n",
    "checkpoint_dir = \"./ckpt\"\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "\n",
    "\n",
    "def make_or_restore_model():\n",
    "    # Either restore the latest model, or create a fresh one\n",
    "    # if there is no checkpoint available.\n",
    "    checkpoints = [checkpoint_dir + \"/\" + name for name in os.listdir(checkpoint_dir)]\n",
    "    print(checkpoints)\n",
    "    if checkpoints:\n",
    "        latest_checkpoint = max(checkpoints, key=os.path.getctime)\n",
    "        print(\"Restoring from\", latest_checkpoint)\n",
    "        return keras.models.load_model(latest_checkpoint)\n",
    "    print(\"Creating a new model\")\n",
    "    return get_compiled_model()\n",
    "\n",
    "\n",
    "model = make_or_restore_model()\n",
    "callbacks = [\n",
    "    # This callback saves a SavedModel every 100 batches.\n",
    "    # We include the training loss in the saved model name.\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_dir + \"/ckpt-loss={loss:.2f}\", save_freq=100\n",
    "    )\n",
    "]\n",
    "model.fit(x_train, y_train, epochs=1, callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6efba92b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T06:40:46.739394Z",
     "start_time": "2021-07-30T06:40:46.704238Z"
    }
   },
   "outputs": [],
   "source": [
    "initial_learning_rate = 0.1\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate, decay_steps=100000, decay_rate=0.96, staircase=True\n",
    ")\n",
    "\n",
    "optimizer = keras.optimizers.RMSprop(learning_rate=lr_schedule)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5615f1ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T06:57:16.308441Z",
     "start_time": "2021-07-30T06:56:48.454169Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "  2/625 [..............................] - ETA: 3:03 - loss: 2.2357 - sparse_categorical_accuracy: 0.1484WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0053s vs `on_train_batch_end` time: 0.5796s). Check your callbacks.\n",
      "625/625 [==============================] - 2s 4ms/step - loss: 0.3693 - sparse_categorical_accuracy: 0.8943 - val_loss: 0.2306 - val_sparse_categorical_accuracy: 0.9282\n",
      "Epoch 2/20\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.1681 - sparse_categorical_accuracy: 0.9506 - val_loss: 0.1746 - val_sparse_categorical_accuracy: 0.9499\n",
      "Epoch 3/20\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.1218 - sparse_categorical_accuracy: 0.9636 - val_loss: 0.1593 - val_sparse_categorical_accuracy: 0.9528\n",
      "Epoch 4/20\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.0968 - sparse_categorical_accuracy: 0.9708 - val_loss: 0.1561 - val_sparse_categorical_accuracy: 0.9543\n",
      "Epoch 5/20\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.0810 - sparse_categorical_accuracy: 0.9761 - val_loss: 0.1426 - val_sparse_categorical_accuracy: 0.9584\n",
      "Epoch 6/20\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.0687 - sparse_categorical_accuracy: 0.9792 - val_loss: 0.1383 - val_sparse_categorical_accuracy: 0.9618\n",
      "Epoch 7/20\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.0593 - sparse_categorical_accuracy: 0.9822 - val_loss: 0.1562 - val_sparse_categorical_accuracy: 0.9572\n",
      "Epoch 8/20\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.0524 - sparse_categorical_accuracy: 0.9843 - val_loss: 0.1302 - val_sparse_categorical_accuracy: 0.9637\n",
      "Epoch 9/20\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.0445 - sparse_categorical_accuracy: 0.9863 - val_loss: 0.1346 - val_sparse_categorical_accuracy: 0.9675\n",
      "Epoch 10/20\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.0390 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.1390 - val_sparse_categorical_accuracy: 0.9660\n",
      "Epoch 11/20\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.0342 - sparse_categorical_accuracy: 0.9897 - val_loss: 0.1516 - val_sparse_categorical_accuracy: 0.9601\n",
      "Epoch 12/20\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.0303 - sparse_categorical_accuracy: 0.9909 - val_loss: 0.1438 - val_sparse_categorical_accuracy: 0.9662\n",
      "Epoch 13/20\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.0254 - sparse_categorical_accuracy: 0.9921 - val_loss: 0.1553 - val_sparse_categorical_accuracy: 0.9650\n",
      "Epoch 14/20\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.0228 - sparse_categorical_accuracy: 0.9932 - val_loss: 0.1549 - val_sparse_categorical_accuracy: 0.9678\n",
      "Epoch 15/20\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.0201 - sparse_categorical_accuracy: 0.9940 - val_loss: 0.1825 - val_sparse_categorical_accuracy: 0.9649\n",
      "Epoch 16/20\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.0175 - sparse_categorical_accuracy: 0.9942 - val_loss: 0.1847 - val_sparse_categorical_accuracy: 0.9644\n",
      "Epoch 17/20\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.0160 - sparse_categorical_accuracy: 0.9953 - val_loss: 0.1914 - val_sparse_categorical_accuracy: 0.9646\n",
      "Epoch 18/20\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.0140 - sparse_categorical_accuracy: 0.9957 - val_loss: 0.1870 - val_sparse_categorical_accuracy: 0.9662\n",
      "Epoch 19/20\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.0136 - sparse_categorical_accuracy: 0.9956 - val_loss: 0.2011 - val_sparse_categorical_accuracy: 0.9660\n",
      "Epoch 20/20\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.0102 - sparse_categorical_accuracy: 0.9969 - val_loss: 0.2064 - val_sparse_categorical_accuracy: 0.9643\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25563fd5f70>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_compiled_model()\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.TensorBoard(\n",
    "    log_dir=\"/full_path_to_your_logs\",\n",
    "    histogram_freq=0,  # How often to log histogram visualizations\n",
    "    embeddings_freq=0,  # How often to log embedding visualizations\n",
    "    update_freq=\"epoch\",\n",
    "    )  \n",
    "]\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=20,\n",
    "    batch_size=64,\n",
    "    callbacks=callbacks,\n",
    "    validation_split=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "87dbfef3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T07:19:39.699868Z",
     "start_time": "2021-07-30T07:18:39.467526Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Timed out waiting for TensorBoard to start. It may still be running as pid 8940."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir /full_path_to_your_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af3a2c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:nlp2]",
   "language": "python",
   "name": "conda-env-nlp2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
